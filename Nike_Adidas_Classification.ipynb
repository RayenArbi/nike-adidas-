{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "498e9d6f",
   "metadata": {},
   "source": [
    "# Nike vs Adidas Image Classification (Colab-ready)\n",
    "\n",
    "This notebook uses **TensorFlow / Keras** with **ResNet50** transfer learning to classify images of Nike vs Adidas shoes.\n",
    "\n",
    "How to use:\n",
    "\n",
    "1. Upload `archive.zip` to Colab and place it in `/content` or mount Google Drive and provide path.\n",
    "2. Run the cells in order. The notebook includes data preparation, model building, training, evaluation, and prediction cells.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a65091",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# OPTIONAL: Mount Google Drive if you want to save models/results there\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# If you uploaded archive.zip to /content or /mnt/data, adjust paths below.\n",
    "DATA_ZIP = \"/mnt/data/archive.zip\"  # adjust if needed in Colab (/content/archive.zip)\n",
    "EXTRACT_DIR = \"/mnt/data/dataset\"   # change if you extract elsewhere\n",
    "print(\"Set DATA_ZIP and EXTRACT_DIR as needed before running unzip/extract cell.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f07a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip dataset (if not already unzipped)\n",
    "import os, zipfile\n",
    "DATA_ZIP = \"/mnt/data/archive.zip\"\n",
    "EXTRACT_DIR = \"/mnt/data/dataset\"\n",
    "if not os.path.exists(EXTRACT_DIR):\n",
    "    os.makedirs(EXTRACT_DIR, exist_ok=True)\n",
    "    if os.path.exists(DATA_ZIP):\n",
    "        with zipfile.ZipFile(DATA_ZIP, 'r') as z:\n",
    "            z.extractall(EXTRACT_DIR)\n",
    "        print(\"Extracted archive.zip to\", EXTRACT_DIR)\n",
    "    else:\n",
    "        print(\"archive.zip not found at\", DATA_ZIP)\n",
    "else:\n",
    "    print(\"Dataset directory already exists at\", EXTRACT_DIR)\n",
    "# show a few files\n",
    "for root, dirs, files in os.walk(EXTRACT_DIR):\n",
    "    print(root, \"->\", len(dirs), \"dirs,\", len(files), \"files\")\n",
    "    for i, f in enumerate(files[:5]):\n",
    "        print(\"   \", f)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8291c9df",
   "metadata": {},
   "source": [
    "## Expected folder structure\n",
    "\n",
    "The notebook expects the dataset to be organized like:\n",
    "\n",
    "```\n",
    "dataset/\n",
    " ├── train/\n",
    " │    ├── nike/\n",
    " │    └── adidas/\n",
    " ├── val/\n",
    "                                │    ├── nike/\n",
    " │    └── adidas/\n",
    " └── test/\n",
    "      ├── nike/\n",
    "      └── adidas/\n",
    "```\n",
    "\n",
    "If your dataset is a single folder with class subfolders (e.g. train & test not present), the notebook includes code to split it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6ed27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Data preparation with ImageDataGenerator\n",
    "import os, shutil, random\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "base_dir = \"/mnt/data/dataset\"  # adjust if necessary\n",
    "# Try to find a train/val/test structure; if not, split automatically.\n",
    "def find_class_folders(base_dir):\n",
    "    # Look for class folders under base_dir or under first-level directories\n",
    "    classes = {}\n",
    "    for entry in os.listdir(base_dir):\n",
    "        p = os.path.join(base_dir, entry)\n",
    "        if os.path.isdir(p):\n",
    "            # check if this looks like a class folder (contains images)\n",
    "            files = [f for f in os.listdir(p) if f.lower().endswith(('.png','.jpg','.jpeg'))]\n",
    "            if files:\n",
    "                classes[entry] = p\n",
    "    return classes\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "if not os.path.exists(train_dir):\n",
    "    # attempt to auto-split if dataset contains class folders directly under base_dir\n",
    "    class_folders = find_class_folders(base_dir)\n",
    "    if class_folders:\n",
    "        print(\"Detected class folders directly under dataset. Creating train/val/test split...\")\n",
    "        # create directories\n",
    "        for split in ['train','val','test']:\n",
    "            os.makedirs(os.path.join(base_dir, split), exist_ok=True)\n",
    "        for cls, cls_path in class_folders.items():\n",
    "            images = [f for f in os.listdir(cls_path) if f.lower().endswith(('.png','.jpg','.jpeg'))]\n",
    "            train_files, temp = train_test_split(images, test_size=0.3, random_state=42)\n",
    "            val_files, test_files = train_test_split(temp, test_size=0.5, random_state=42)\n",
    "            for split_name, files in zip(['train','val','test'], [train_files, val_files, test_files]):\n",
    "                dest_cls = os.path.join(base_dir, split_name, cls)\n",
    "                os.makedirs(dest_cls, exist_ok=True)\n",
    "                for fname in files:\n",
    "                    src = os.path.join(cls_path, fname)\n",
    "                    dst = os.path.join(dest_cls, fname)\n",
    "                    if not os.path.exists(dst):\n",
    "                        shutil.copy(src, dst)\n",
    "        print(\"Split created at:\", base_dir)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Couldn't find class folders under {base_dir}. Please arrange your data or adjust base_dir.\")\n",
    "\n",
    "# Setup ImageDataGenerator\n",
    "IMG_SIZE = (224,224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1,\n",
    "                                   shear_range=0.1,\n",
    "                                   zoom_range=0.1,\n",
    "                                   horizontal_flip=True,\n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    os.path.join(base_dir, 'train'),\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = test_datagen.flow_from_directory(\n",
    "    os.path.join(base_dir, 'val'),\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    os.path.join(base_dir, 'test'),\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=1,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"Classes:\", train_generator.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a33c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build model using ResNet50 (transfer learning)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "num_classes = 2  # Nike vs Adidas\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "base_model.trainable = False  # freeze base\n",
    "\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(learning_rate=1e-4),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe72bf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training\n",
    "EPOCHS = 10  # increase when you run for real\n",
    "checkpoint_path = \"/mnt/data/resnet50_shoes_best.h5\"\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1),\n",
    "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "# Save final model\n",
    "model.save('/mnt/data/resnet50_shoes_final.h5')\n",
    "print('Saved model to /mnt/data/resnet50_shoes_final.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49044cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluation on test set\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load best model if checkpoint exists\n",
    "try:\n",
    "    model.load_weights('/mnt/data/resnet50_shoes_best.h5')\n",
    "    print('Loaded best weights.')\n",
    "except Exception as e:\n",
    "    print('Could not load best weights:', e)\n",
    "\n",
    "# Predictions\n",
    "test_steps = test_generator.samples\n",
    "preds = model.predict(test_generator, steps=test_steps, verbose=1)\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "y_true = test_generator.classes\n",
    "\n",
    "# Report\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_true, y_pred, target_names=list(train_generator.class_indices.keys())))\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(cm, interpolation='nearest')\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(train_generator.class_indices)), list(train_generator.class_indices.keys()), rotation=45)\n",
    "plt.yticks(range(len(train_generator.class_indices)), list(train_generator.class_indices.keys()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "for (i, j), val in np.ndenumerate(cm):\n",
    "    plt.text(j, i, val, ha='center', va='center', color='white' if val>cm.max()/2 else 'black')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b128ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot training curves\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history.get('accuracy', [])\n",
    "val_acc = history.history.get('val_accuracy', [])\n",
    "loss = history.history.get('loss', [])\n",
    "val_loss = history.history.get('val_loss', [])\n",
    "\n",
    "epochs_range = range(1, len(acc)+1)\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(epochs_range, acc, label='Train Acc')\n",
    "plt.plot(epochs_range, val_acc, label='Val Acc')\n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(epochs_range, loss, label='Train Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Val Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aea7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predict on custom images - upload an image in Colab and set IMAGE_PATH\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "IMAGE_PATH = None  # set to '/content/my_shoe.jpg' or path in /mnt/data\n",
    "\n",
    "def predict_image(img_path, model, target_size=(224,224)):\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    x = image.img_to_array(img)\n",
    "    x = x / 255.0\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    preds = model.predict(x)\n",
    "    cls_idx = np.argmax(preds, axis=1)[0]\n",
    "    class_labels = list(train_generator.class_indices.keys())\n",
    "    return class_labels[cls_idx], preds[0][cls_idx]\n",
    "\n",
    "print('Set IMAGE_PATH to an image file and run predict_image(IMAGE_PATH, model)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98be4dcc",
   "metadata": {},
   "source": [
    "### Dataset extraction\n",
    "\n",
    "`archive.zip` was found and extracted to `/mnt/data/dataset`. Top-level folders:\n",
    "\n",
    "- `/mnt/data/dataset`: dirs=['test', 'train', 'validation'], files_sample=['labelnames.csv']\n",
    "- `/mnt/data/dataset/test`: dirs=['adidas', 'nike'], files_sample=[]\n",
    "- `/mnt/data/dataset/test/adidas`: dirs=[], files_sample=['Adidas (18).jpg', 'Adidas (19).jpg', 'Adidas (20).jpg', 'Adidas (21).JPG', 'Adidas (22).jpg']\n",
    "- `/mnt/data/dataset/test/nike`: dirs=[], files_sample=['Image_10.jpg', 'Image_100.jpg', 'Image_110.jpg', 'Image_120.jpg', 'Image_130.jpg']\n",
    "- `/mnt/data/dataset/train`: dirs=['adidas', 'nike'], files_sample=[]\n",
    "- `/mnt/data/dataset/train/adidas`: dirs=[], files_sample=['Adidas (1).jpg', 'Adidas (10).jpg', 'Adidas (11).jpg', 'Adidas (12).jpg', 'Adidas (13).jpg']\n",
    "- `/mnt/data/dataset/train/nike`: dirs=[], files_sample=['Image_1.jpg', 'Image_101.jpg', 'Image_102.jpg', 'Image_103.jpg', 'Image_104.JPG']\n",
    "- `/mnt/data/dataset/validation`: dirs=['adidas', 'nike'], files_sample=[]\n",
    "- `/mnt/data/dataset/validation/adidas`: dirs=[], files_sample=['adidas_ (149).jpg', 'adidas_ (150).jpg', 'adidas_ (151).jpg', 'adidas_ (152).jpg', 'adidas_ (153).jpg']\n",
    "- `/mnt/data/dataset/validation/nike`: dirs=[], files_sample=['Image_261.jpg', 'Image_262.jpg', 'Image_263.jpg', 'Image_264.jpg', 'Image_265.jpg']\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
